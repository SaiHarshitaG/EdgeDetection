# EdgeDetector â€” Android + JNI + OpenCV + OpenGL + TypeScript Viewer

**Author:** Sai Harshita Ganti  
**Assignment:** Software Engineering Intern (R&D) â€” Image Processing Prototype  
**Platform:** Android (Java + C++), Web (TypeScript)

---

## ğŸš€ Project Overview
This project implements a **real-time image processing pipeline** on Android using **native C++** (via JNI) and **OpenGL ES rendering**.  
It demonstrates the integration of multiple system components:
- Android **Camera2 API** for capturing frames
- **JNI bridge** for communication between Java and native code
- **C++ (OpenCV)** for performing **edge detection** on live camera frames
- **OpenGL ES** for rendering processed frames on the device
- A **TypeScript web viewer** to visualize processed images and FPS

This structure mirrors real-world **embedded vision and R&D prototype** systems â€” where native performance, platform integration, and visualization are equally important.

---

## ğŸ§© Architecture Diagram
```text
Camera2 (NV21 Frames)
        â†“
  JNI Bridge (Java â†” C++)
        â†“
 OpenCV Native Processing (Canny Edge)
        â†“
 RGBA Output Buffer
        â†“
  OpenGL Renderer (GLSurfaceView)
        â†“
 Display on Android Device
```
Additionally, the web viewer (`/web`) allows displaying a static processed frame with FPS overlay for simulation or demo purposes.

---

## ğŸ§  Tech Stack
| Layer | Technology |
|-------|-------------|
| Android Frontend | Java, Camera2, TextureView, GLSurfaceView |
| Native Processing | C++, OpenCV (Canny edge detection), JNI |
| Rendering | OpenGL ES 2.0 |
| Web Visualization | TypeScript, HTML, CSS |

---

## âš™ï¸ Features
- Simulated NV21 â†’ RGBA grayscale frame conversion (fallback when OpenCV not configured)
- Modular CMake + JNI setup for native libraries
- Simple OpenGL renderer for real-time frame drawing
- Extendable to integrate any OpenCV transformation (Canny, Sobel, etc.)
- Optional TypeScript web viewer with FPS and resolution display

---

## ğŸ“ Project Structure
```text
EdgeDetectorProject/
â”‚
â”œâ”€â”€ app/                      # Android app module
â”‚   â”œâ”€â”€ src/main/java/com/example/edgedetector/
â”‚   â”‚   â”œâ”€â”€ MainActivity.java          # Camera2 + GL integration
â”‚   â”‚   â”œâ”€â”€ Camera2Helper.java         # Frame source (simulated)
â”‚   â”‚   â”œâ”€â”€ GLRenderer.java            # OpenGL rendering
â”‚   â”‚   â”œâ”€â”€ GLSurfaceViewWrapper.java  # GLSurfaceView wrapper
â”‚   â”‚   â””â”€â”€ NativeBridge.java          # JNI bridge
â”‚   â”‚
â”‚   â”œâ”€â”€ src/main/cpp/
â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt             # Native build config
â”‚   â”‚   â””â”€â”€ native-lib.cpp             # C++ image processing
â”‚   â”‚
â”‚   â””â”€â”€ src/main/AndroidManifest.xml
â”‚
â”œâ”€â”€ web/                     # Optional TypeScript web viewer
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ ts/app.ts
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ app.js (compiled)
â”‚
â””â”€â”€ README.md
```
---

## ğŸ› ï¸ Dependencies

### Android Requirements
- Android Studio (latest)
- Android SDK (API Level â‰¥ 33)
- Android NDK + CMake (via SDK Tools)
- Physical Android device (for Camera & JNI)
- Optional: OpenCV Android SDK (for real edge detection)

### Web Requirements
- Node.js & npm
- TypeScript (`npm install -g typescript`)

---

## ğŸ”§ Build & Run (Android)
1. Open the project folder in **Android Studio**
2. Ensure NDK and CMake are installed
3. Build the project (`Build â†’ Make Project`)
4. Connect an Android device and run (`Run â†’ Run 'app'`)
5. Grant camera permission if requested

> The app simulates NV21 frames by default.  
> To enable real processing, add OpenCV SDK and replace the stub logic in `native-lib.cpp`.

---

## ğŸŒ Build & Run (Web)
1. Open terminal in `/web` folder
2. Run:
   ```bash
   npm install -g typescript
   npx tsc -p tsconfig.json
3. Open index.html in a browser
